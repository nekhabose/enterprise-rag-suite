# ğŸ“ AI Study Assistant - Advanced RAG Platform

A production-grade educational platform featuring a modular Retrieval-Augmented Generation (RAG) system with multiple configurable strategies for chunking, embedding, vector storage, retrieval, and LLM providers.

## ğŸŒŸ Features

### Core Functionality
- ğŸ“„ **PDF Document Processing** - Upload and index educational materials
- ğŸ’¬ **Intelligent Chat Interface** - Ask questions about your documents
- ğŸ” **User Authentication** - Secure JWT-based auth system
- ğŸ¯ **Multi-Provider Support** - OpenAI, Groq, and more

### Advanced RAG Features
- **7 Chunking Strategies**: Fixed-size, Page-based, Paragraph, Semantic, Parent-child, Sentence, Recursive
- **Multiple Embedding Models**: OpenAI, Sentence Transformers, HuggingFace (coming soon)
- **Vector Store Options**: PostgreSQL+pgvector, FAISS, ChromaDB, Pinecone (coming soon)
- **Retrieval Strategies**: Semantic, BM25, Hybrid (coming soon)
- **LLM Providers**: OpenAI GPT, Groq Llama, Anthropic Claude, Google Gemini (coming soon)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FRONTEND (React + TypeScript)             â”‚
â”‚  â€¢ Auth UI                                               â”‚
â”‚  â€¢ Document Upload with Strategy Selection               â”‚
â”‚  â€¢ Chat Interface                                        â”‚
â”‚  â€¢ Provider Configuration Dropdowns                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ REST API
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           BACKEND (Node.js + TypeScript)                 â”‚
â”‚  â€¢ JWT Authentication                                    â”‚
â”‚  â€¢ Document Management                                   â”‚
â”‚  â€¢ Chat Session Handling                                 â”‚
â”‚  â€¢ Configuration Pass-through                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AI SERVICE (Python + FastAPI)                  â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          MODULAR RAG PIPELINE                      â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚  1. CHUNKING (Factory Pattern)                     â”‚  â”‚
â”‚  â”‚     â”œâ”€ Fixed Size      (500 words + overlap)      â”‚  â”‚
â”‚  â”‚     â”œâ”€ Page Based      (PDF page boundaries)      â”‚  â”‚
â”‚  â”‚     â”œâ”€ Paragraph       (Natural breaks)           â”‚  â”‚
â”‚  â”‚     â”œâ”€ Semantic        (Topic boundaries)         â”‚  â”‚
â”‚  â”‚     â”œâ”€ Parent-Child    (Hierarchical)             â”‚  â”‚
â”‚  â”‚     â”œâ”€ Sentence        (Sentence groups)          â”‚  â”‚
â”‚  â”‚     â””â”€ Recursive       (Multi-level splits)       â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚  2. EMBEDDING (Factory Pattern)                    â”‚  â”‚
â”‚  â”‚     â”œâ”€ OpenAI          (text-embedding-ada-002)   â”‚  â”‚
â”‚  â”‚     â”œâ”€ Simple Text     (Character-based)          â”‚  â”‚
â”‚  â”‚     â””â”€ [More coming]   (Sentence Transformers)    â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚  3. VECTOR STORE                                   â”‚  â”‚
â”‚  â”‚     â”œâ”€ PostgreSQL      (pgvector extension)       â”‚  â”‚
â”‚  â”‚     â””â”€ [More coming]   (FAISS, ChromaDB, etc)     â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚  4. RETRIEVAL                                      â”‚  â”‚
â”‚  â”‚     â”œâ”€ Semantic        (Cosine similarity)        â”‚  â”‚
â”‚  â”‚     â””â”€ [More coming]   (BM25, Hybrid, MMR)        â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚  5. LLM GENERATION                                 â”‚  â”‚
â”‚  â”‚     â”œâ”€ OpenAI          (GPT-3.5, GPT-4)           â”‚  â”‚
â”‚  â”‚     â”œâ”€ Groq            (Llama 3.3 70B)            â”‚  â”‚
â”‚  â”‚     â””â”€ [More coming]   (Claude, Gemini, Cohere)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DATABASE (PostgreSQL + pgvector)                 â”‚
â”‚  â€¢ User accounts                                         â”‚
â”‚  â€¢ Documents & chunks                                    â”‚
â”‚  â€¢ Vector embeddings (1536-dim)                          â”‚
â”‚  â€¢ Chat conversations & messages                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.10+
- PostgreSQL 14+ with pgvector extension
- API Keys: OpenAI (optional) or Groq (free)

### Installation

**1. Clone and Setup Database**
```bash
git clone <your-repo-url>
cd edu-platform

# Create database
createdb edu_platform
psql edu_platform -f database/schema.sql
```

**2. Python AI Service**
```bash
cd ai-service
python3.10 -m venv venv
source venv/bin/activate  # Mac/Linux
# venv\Scripts\activate  # Windows

pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your API keys
```

**3. Node.js Backend**
```bash
cd ../backend
npm install

# Configure environment
cp .env.example .env
# Edit .env and add your settings
```

**4. React Frontend**
```bash
cd ../frontend
npm install

# Configure environment
cp .env.example .env
```

### Running the Application

**Terminal 1 - Python AI Service:**
```bash
cd ai-service
source venv/bin/activate
python main.py
# Running on http://localhost:${AI_SERVICE_PORT:-8000}
```

**Terminal 2 - Node.js Backend:**
```bash
cd backend
npm run dev
# Running on http://localhost:${PORT:-3000}
```

**Terminal 3 - React Frontend:**
```bash
cd frontend
npm start
# Running on http://localhost:${PORT:-3001}
```
Visit your configured frontend URL (default **http://localhost:3001**) in your browser.

## ğŸ“š Usage Guide

### Basic Workflow
1. **Sign Up** - Create an account
2. **Select AI Provider** - Choose OpenAI or Groq from dropdown
3. **Upload Documents** - Upload PDF files
4. **Choose Chunking Strategy** - Select how to split your documents
5. **Start Chatting** - Ask questions about your materials

### Chunking Strategies Explained

| Strategy | Best For | Description |
|----------|----------|-------------|
| **Fixed Size** | General documents | 500 words with 50-word overlap |
| **Page Based** | Structured PDFs | Preserves page boundaries |
| **Paragraph** | Articles, books | Keeps paragraphs intact |
| **Semantic** | Technical docs | Splits by topic/headers |
| **Parent-Child** | Context retention | Hierarchical chunks |
| **Sentence** | Precise retrieval | Groups sentences |
| **Recursive** | Complex docs | Multi-level splitting |

### API Endpoints

#### Authentication
- `POST /auth/signup` - Create account
- `POST /auth/login` - Login

#### Documents
- `GET /documents` - List documents
- `POST /documents/upload` - Upload PDF (with strategy selection)
- `DELETE /documents/:id` - Delete document

#### Chat
- `GET /conversations` - List conversations
- `POST /conversations` - Create conversation
- `POST /chat/send` - Send message

#### Configuration
- `GET /ai/chunking-strategies` - List available strategies
- `GET /ai/providers` - List available AI providers

## ğŸ› ï¸ Tech Stack

### Backend Services
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Backend API | Node.js + TypeScript + Express | REST API server |
| AI Service | Python + FastAPI | RAG pipeline |
| Database | PostgreSQL 14 | Data persistence |
| Vector Store | pgvector extension | Vector similarity search |

### AI/ML Stack
| Component | Options | Notes |
|-----------|---------|-------|
| **Chunking** | 7 strategies | Factory pattern |
| **Embeddings** | OpenAI, Simple Text | Extensible |
| **Vector DB** | pgvector | IVFFlat indexing |
| **Retrieval** | Semantic (cosine) | More coming |
| **LLM** | OpenAI GPT, Groq Llama | Multi-provider |

### Frontend
| Component | Technology |
|-----------|-----------|
| Framework | React 18 + TypeScript |
| HTTP Client | Axios |
| Styling | Custom CSS |
| State | React Hooks |

## ğŸ“ Project Structure

```
edu-platform/
â”œâ”€â”€ ai-service/              # Python AI microservice
â”‚   â”œâ”€â”€ chunking/           # Modular chunking strategies
â”‚   â”‚   â”œâ”€â”€ base_chunker.py
â”‚   â”‚   â”œâ”€â”€ fixed_size_chunker.py
â”‚   â”‚   â”œâ”€â”€ page_based_chunker.py
â”‚   â”‚   â”œâ”€â”€ paragraph_chunker.py
â”‚   â”‚   â”œâ”€â”€ semantic_chunker.py
â”‚   â”‚   â”œâ”€â”€ parent_child_chunker.py
â”‚   â”‚   â”œâ”€â”€ sentence_chunker.py
â”‚   â”‚   â”œâ”€â”€ recursive_chunker.py
â”‚   â”‚   â””â”€â”€ chunking_factory.py
â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ .env.example        # Environment template
â”‚
â”œâ”€â”€ backend/                # Node.js backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ server.ts       # Express application
â”‚   â”œâ”€â”€ package.json        # Node dependencies
â”‚   â”œâ”€â”€ tsconfig.json       # TypeScript config
â”‚   â””â”€â”€ .env.example        # Environment template
â”‚
â”œâ”€â”€ frontend/               # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx         # Main application
â”‚   â”‚   â””â”€â”€ App.css         # Styles
â”‚   â”œâ”€â”€ package.json        # Dependencies
â”‚   â””â”€â”€ .env.example        # Environment template
â”‚
â”œâ”€â”€ database/               # Database schema
â”‚   â””â”€â”€ schema.sql          # PostgreSQL schema
â”‚
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Configuration

### Environment Variables
Create env files first:
```bash
cp ai-service/.env.example ai-service/.env
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env
```

Where to add API keys:
- Add LLM keys in `ai-service/.env`
- Add backend secrets/DB in `backend/.env`
- Add frontend API URL and frontend dev port in `frontend/.env`

Templates:

**`ai-service/.env`**
```env
AI_SERVICE_HOST=0.0.0.0
AI_SERVICE_PORT=8000

FRONTEND_PORT=3001
FRONTEND_URL=http://localhost:3001
# CORS_ORIGINS=http://localhost:3001,http://127.0.0.1:3001

DATABASE_URL=postgresql://localhost:5432/edu_platform

OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
COHERE_API_KEY=...
ANTHROPIC_API_KEY=...
GOOGLE_API_KEY=...
TOGETHER_API_KEY=...
```

**`backend/.env`**
```env
PORT=3000
DATABASE_URL=postgresql://localhost:5432/edu_platform
JWT_SECRET=replace-with-a-strong-secret

# Use either AI_SERVICE_URL or AI_SERVICE_HOST + AI_SERVICE_PORT
AI_SERVICE_URL=http://localhost:8000
# AI_SERVICE_HOST=localhost
# AI_SERVICE_PORT=8000
```

**`frontend/.env`**
```env
PORT=3001
REACT_APP_API_URL=http://localhost:3000
# Optional fallback used when REACT_APP_API_URL is not set
REACT_APP_BACKEND_PORT=3000
```

Port configuration:
- Frontend dev server port: `frontend/.env` -> `PORT`
- Backend API port: `backend/.env` -> `PORT`
- AI service port: `ai-service/.env` -> `AI_SERVICE_PORT` (or `PORT`)

If you change ports:
1. Set `backend/.env` `PORT=<backend_port>`
2. Set `ai-service/.env` `AI_SERVICE_PORT=<ai_port>`
3. Set `frontend/.env` `PORT=<frontend_port>`
4. Point frontend to backend with `REACT_APP_API_URL=http://localhost:<backend_port>`
5. Point backend to AI with `AI_SERVICE_URL=http://localhost:<ai_port>` (or host+port vars)

## ğŸ§ª Testing

**Test Chunking Module:**
```bash
cd ai-service
python test_chunking.py
```

**Test API Endpoints:**
```bash
# Test AI service
curl http://localhost:8000/

# Test backend
curl http://localhost:3000/

# List chunking strategies
curl http://localhost:8000/ai/chunking-strategies
```

## ğŸ¯ Roadmap

### Phase 2: Rich Ingestion (Coming Soon)
- âœ… YouTube video ingestion
- âœ… Research paper handling
- âœ… Metadata tagging (subject/year)
- âœ… Advanced filtering

### Phase 3: AI Learning Tools (Coming Soon)
- âœ… Quiz generation
- âœ… AI-powered grading
- âœ… Study recommendations

### Phase 4: Enterprise Features (Coming Soon)
- âœ… LMS integration (LTI)
- âœ… Multi-tenant support
- âœ… Admin portal
- âœ… Analytics dashboard

### Phase 5: Advanced RAG (In Progress)
- â³ More embedding models
- â³ Multiple vector stores
- â³ Hybrid retrieval
- â³ More LLM providers

## ğŸ¤ Contributing

This is a learning project. Feel free to:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¨â€ğŸ’» Author

Built as an educational project to demonstrate:
- Modern full-stack architecture
- Advanced RAG techniques
- Modular design patterns
- Production-ready code

## ğŸ™ Acknowledgments

- OpenAI for GPT and embeddings API
- Groq for fast LLM inference
- PostgreSQL team for pgvector extension
- FastAPI and React communities

---

**Questions?** Open an issue or reach out!
